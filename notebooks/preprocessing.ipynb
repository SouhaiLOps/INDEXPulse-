{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "16781df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import src.download_yf as dlyf\n",
    "import src.preprocessing as prep\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import src.arima_train as arima_train\n",
    "from statsmodels.tsa.arima.model import ARIMAResults\n",
    "\n",
    "cwd = os.getcwd()\n",
    "project_root=Path(cwd).parent\n",
    "data_dir = project_root / \"data\"\n",
    "models_dir = project_root / \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c550c",
   "metadata": {},
   "source": [
    "##  I ) --------------------- Test >>  src.download_yf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2adffc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['^FCHI']: YFPricesMissingError('possibly delisted; no price data found  (1d 2025-11-22 -> 2025-11-24)')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tidy existant chargé : /Users/souhail/projets-ml/indexpulse/data/raw/ohlcv_10y.parquet\n",
      "[INFO] Dernière date FCHI dans le parquet tidy : 2025-11-21 00:00:00\n",
      "[INFO] Téléchargement FCHI du 2025-11-22 au 2025-11-24…\n",
      "[WARN] yf.download a renvoyé vide pour ['^FCHI'] entre 2025-11-22 et 2025-11-24\n",
      "[WARN] Aucunes nouvelles lignes reçues pour FCHI.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>^FCHI</td>\n",
       "      <td>8155.930176</td>\n",
       "      <td>8176.100098</td>\n",
       "      <td>8109.819824</td>\n",
       "      <td>8119.020020</td>\n",
       "      <td>8119.020020</td>\n",
       "      <td>42960200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>^FCHI</td>\n",
       "      <td>8017.729980</td>\n",
       "      <td>8032.509766</td>\n",
       "      <td>7925.060059</td>\n",
       "      <td>7967.930176</td>\n",
       "      <td>7967.930176</td>\n",
       "      <td>68564200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>2025-11-19</td>\n",
       "      <td>^FCHI</td>\n",
       "      <td>7964.770020</td>\n",
       "      <td>8005.750000</td>\n",
       "      <td>7919.359863</td>\n",
       "      <td>7953.770020</td>\n",
       "      <td>7953.770020</td>\n",
       "      <td>55042800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2025-11-20</td>\n",
       "      <td>^FCHI</td>\n",
       "      <td>8044.850098</td>\n",
       "      <td>8057.700195</td>\n",
       "      <td>7981.069824</td>\n",
       "      <td>7981.069824</td>\n",
       "      <td>7981.069824</td>\n",
       "      <td>60357000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>^FCHI</td>\n",
       "      <td>7881.100098</td>\n",
       "      <td>7996.459961</td>\n",
       "      <td>7875.870117</td>\n",
       "      <td>7982.649902</td>\n",
       "      <td>7982.649902</td>\n",
       "      <td>64784800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date ticker         open         high          low        close  \\\n",
       "2556 2025-11-17  ^FCHI  8155.930176  8176.100098  8109.819824  8119.020020   \n",
       "2557 2025-11-18  ^FCHI  8017.729980  8032.509766  7925.060059  7967.930176   \n",
       "2558 2025-11-19  ^FCHI  7964.770020  8005.750000  7919.359863  7953.770020   \n",
       "2559 2025-11-20  ^FCHI  8044.850098  8057.700195  7981.069824  7981.069824   \n",
       "2560 2025-11-21  ^FCHI  7881.100098  7996.459961  7875.870117  7982.649902   \n",
       "\n",
       "        adj_close      volume  \n",
       "2556  8119.020020  42960200.0  \n",
       "2557  7967.930176  68564200.0  \n",
       "2558  7953.770020  55042800.0  \n",
       "2559  7981.069824  60357000.0  \n",
       "2560  7982.649902  64784800.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dlyf)\n",
    "tidy_all = dlyf.update_fchi_tidy()\n",
    "tidy_all[tidy_all[\"ticker\"] == \"^FCHI\"].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4cb329",
   "metadata": {},
   "source": [
    "## II ) -------------------------- Test >>  src.preprocessing.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6b22947a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Features FCHI écrites dans : /Users/souhail/projets-ml/indexpulse/data/processed/FCHI_features_h1d.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           date ticker         open         high          low        close  \\\n",
       " 2355 2025-11-14  ^FCHI  8186.140137  8202.480469  8084.229980  8170.089844   \n",
       " 2356 2025-11-17  ^FCHI  8155.930176  8176.100098  8109.819824  8119.020020   \n",
       " 2357 2025-11-18  ^FCHI  8017.729980  8032.509766  7925.060059  7967.930176   \n",
       " 2358 2025-11-19  ^FCHI  7964.770020  8005.750000  7919.359863  7953.770020   \n",
       " 2359 2025-11-20  ^FCHI  8044.850098  8057.700195  7981.069824  7981.069824   \n",
       " \n",
       "         adj_close      volume  dow  month  ...       ema200  volstd200  \\\n",
       " 2355  8170.089844  54654300.0    4     11  ...  7840.150927   0.010450   \n",
       " 2356  8119.020020  42960200.0    0     11  ...  7842.925744   0.010459   \n",
       " 2357  7967.930176  68564200.0    1     11  ...  7844.169569   0.010492   \n",
       " 2358  7953.770020  55042800.0    2     11  ...  7845.260121   0.010488   \n",
       " 2359  7981.069824  60357000.0    3     11  ...  7846.611461   0.010487   \n",
       " \n",
       "       vol_sma200    vol_lag1    vol_lag2    vol_lag5   vol_lag10         atr  \\\n",
       " 2355  67610487.5  54230000.0  61916100.0  52404200.0  60682000.0   95.577218   \n",
       " 2356  67505916.5  54654300.0  54230000.0  52949300.0  47263500.0   97.480818   \n",
       " 2357  67327108.0  42960200.0  54654300.0  47538300.0  54448200.0  108.455776   \n",
       " 2358  67167644.5  68564200.0  42960200.0  61916100.0  49985700.0  108.047956   \n",
       " 2359  67122602.5  55042800.0  68564200.0  54230000.0  62779100.0  111.552979   \n",
       " \n",
       "       target_ret  target_logret  \n",
       " 2355   -0.006251      -0.006270  \n",
       " 2356   -0.018609      -0.018785  \n",
       " 2357   -0.001777      -0.001779  \n",
       " 2358    0.003432       0.003426  \n",
       " 2359    0.000198       0.000198  \n",
       " \n",
       " [5 rows x 55 columns],\n",
       " (2360, 55))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(prep)\n",
    "feat_fchi = prep.preprocess_cac40_from_tidy(tidy_all)\n",
    "feat_fchi.tail(), feat_fchi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d55c9",
   "metadata": {},
   "source": [
    "## III ) ---------------------- Test >>> arima_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "38f4028f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split temporel : train=1653, val=354, test=353, n_dates=2360\n",
      "Séries : train=1653, val=354, test=353\n",
      "ARIMA VAL RMSE=0.008252   MAE=0.006257\n",
      "ARIMA TEST RMSE=0.009796   MAE=0.007219\n",
      "Modèle ARIMA sauvegardé sous : /Users/souhail/projets-ml/indexpulse/models/arima_logret1_FCHI.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "/Users/souhail/projets-ml/indexpulse/.venv/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse_val': 0.008251699693177503,\n",
       " 'mae_val': 0.006257279383915757,\n",
       " 'rmse_test': 0.009796097597593959,\n",
       " 'mae_test': 0.007218910492449248,\n",
       " 'model_path': PosixPath('/Users/souhail/projets-ml/indexpulse/models/arima_logret1_FCHI.pkl')}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(arima_train)\n",
    "metrics = arima_train.train_arima_logret1()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b6e68e",
   "metadata": {},
   "source": [
    "## IV ) --------- Model summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "484dc2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                logret1   No. Observations:                 2007\n",
      "Model:                 ARIMA(1, 0, 1)   Log Likelihood                6139.108\n",
      "Date:                Mon, 24 Nov 2025   AIC                         -12270.215\n",
      "Time:                        18:11:11   BIC                         -12247.798\n",
      "Sample:                             0   HQIC                        -12261.985\n",
      "                               - 2007                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0003      0.000      0.982      0.326      -0.000       0.001\n",
      "ar.L1         -0.0034      1.186     -0.003      0.998      -2.329       2.322\n",
      "ma.L1         -0.0062      1.190     -0.005      0.996      -2.339       2.326\n",
      "sigma2         0.0001   1.51e-06     85.276      0.000       0.000       0.000\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):             20311.99\n",
      "Prob(Q):                              0.98   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               2.05   Skew:                            -1.00\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        18.46\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "model_path = models_dir/\"arima_logret1_FCHI.pkl\"\n",
    "model = ARIMAResults.load(model_path)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f34ff45",
   "metadata": {},
   "source": [
    "# ----------------------------\n",
    "# ----------------------------\n",
    "# ----------------------------\n",
    "# ----------------------------\n",
    "# ----------------------------\n",
    "# ----------------------------\n",
    "# ----------------------------\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed6176",
   "metadata": {},
   "source": [
    "## 1) Téléchargements : Appel multi-tickers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa00fed",
   "metadata": {},
   "source": [
    "## 2) Format Tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008375df",
   "metadata": {},
   "source": [
    "##  3) Feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c70838",
   "metadata": {},
   "source": [
    "#### Fonctions utilitaires "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901ef95",
   "metadata": {},
   "source": [
    "TICKERS = [\"^GSPC\", \"^FCHI\", \"^STOXX50E\"]  # déjà téléchargés dans `tidy`\n",
    "\n",
    "# Fenêtres & lags de base (ajuste si besoin)\n",
    "FE_WINDOWS = [5, 10, 20, 50, 100, 200]\n",
    "FE_LAGS = [1, 2, 5, 10]\n",
    "HORIZON_D = 1  # on prédit le retour à J+1\n",
    "\n",
    "def add_calendar_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    di = df[\"date\"]\n",
    "    df[\"dow\"] = di.dt.dayofweek        # 0=Mon ... 4=Fri\n",
    "    df[\"month\"] = di.dt.month\n",
    "    # .is_month_end / .is_quarter_end\n",
    "    df[\"is_month_end\"] = di.dt.is_month_end.astype(int)\n",
    "    df[\"is_quarter_end\"] = di.dt.is_quarter_end.astype(int)\n",
    "    # semaine ISO et jour de l'année (optionnel)\n",
    "    iso = di.dt.isocalendar()\n",
    "    df[\"weekofyear\"] = iso.week.astype(int)\n",
    "    df[\"dayofyear\"] = di.dt.dayofyear\n",
    "    return df\n",
    "\n",
    "def add_return_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # retours basés sur CLOSE\n",
    "    df[\"ret1\"] = df[\"close\"].pct_change()\n",
    "    df[\"logret1\"] = np.log(df[\"close\"] / df[\"close\"].shift(1))\n",
    "    # lags de retours\n",
    "    for L in FE_LAGS:\n",
    "        df[f\"ret_lag{L}\"] = df[\"ret1\"].shift(L)\n",
    "        df[f\"logret_lag{L}\"] = df[\"logret1\"].shift(L)\n",
    "    return df\n",
    "\n",
    "def add_ma_vol_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # SMA/EMA sur CLOSE + volatilité (std des retours) + volume laggé\n",
    "    for w in FE_WINDOWS:\n",
    "        df[f\"sma{w}\"] = df[\"close\"].rolling(w, min_periods=w).mean()\n",
    "        df[f\"ema{w}\"] = df[\"close\"].ewm(span=w, adjust=False, min_periods=w).mean()\n",
    "        df[f\"volstd{w}\"] = df[\"ret1\"].rolling(w, min_periods=w).std()\n",
    "        df[f\"vol_sma{w}\"] = df[\"volume\"].rolling(w, min_periods=w).mean()\n",
    "    for L in FE_LAGS:\n",
    "        df[f\"vol_lag{L}\"] = df[\"volume\"].shift(L)\n",
    "    return df\n",
    "\n",
    "def add_atr(df: pd.DataFrame, n: int = 14) -> pd.DataFrame:\n",
    "    # True Range = max(high-low, |high-prev_close|, |low-prev_close|)\n",
    "    prev_close = df[\"close\"].shift(1)\n",
    "    tr = pd.concat([\n",
    "        (df[\"high\"] - df[\"low\"]).abs(),\n",
    "        (df[\"high\"] - prev_close).abs(),\n",
    "        (df[\"low\"] - prev_close).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "    df[\"atr\"] = tr.rolling(n, min_periods=n).mean()\n",
    "    return df\n",
    "\n",
    "def make_target(df: pd.DataFrame, horizon: int = 1) -> pd.DataFrame:\n",
    "    # target = retour futur sur CLOSE\n",
    "    df[\"target_ret\"] = df[\"close\"].pct_change(horizon).shift(-horizon)\n",
    "    df[\"target_logret\"] = (np.log(df[\"close\"] / df[\"close\"].shift(horizon))).shift(-horizon)\n",
    "    return df\n",
    "\n",
    "def build_features_one_ticker(tidy_one: pd.DataFrame, horizon: int = 1) -> pd.DataFrame:\n",
    "    df = tidy_one.sort_values(\"date\").copy()\n",
    "    df = add_calendar_features(df)\n",
    "    df = add_return_features(df)\n",
    "    df = add_ma_vol_features(df)\n",
    "    df = add_atr(df, n=14)\n",
    "    df = make_target(df, horizon=horizon)\n",
    "\n",
    "    # Nettoyage\n",
    "    need_cols = [\"ret1\", \"logret1\", \"atr\", \"target_ret\"]\n",
    "    need_cols += [f\"sma{w}\" for w in FE_WINDOWS] + [f\"volstd{w}\" for w in FE_WINDOWS]\n",
    "    df = df.dropna(subset=need_cols).reset_index(drop=True)\n",
    "\n",
    "    # ⚠️ Pas de standardisation ici : on garde les vraies échelles\n",
    "    # (on pourra scaler dynamiquement plus tard dans le pipeline de modélisation)\n",
    "\n",
    "    return df\n",
    "\n",
    "features_by_ticker = {}\n",
    "for t in TICKERS:\n",
    "    one = tidy[tidy[\"ticker\"] == t].copy()\n",
    "    feat = build_features_one_ticker(one, horizon=HORIZON_D)\n",
    "    features_by_ticker[t] = feat\n",
    "    print(t, feat.shape, \"de\", one.shape)\n",
    "\n",
    "# Exemples d’aperçu\n",
    "features_by_ticker[\"^GSPC\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7a356",
   "metadata": {},
   "source": [
    "df = df_cac.copy()\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "\n",
    "# dates uniques triées\n",
    "unique_dates = df[\"date\"].sort_values().unique()\n",
    "n_dates = len(unique_dates)\n",
    "train_end = unique_dates[int(0.7 * n_dates)]   # ~70% des dates\n",
    "val_end   = unique_dates[int(0.85 * n_dates)]  # ~15% val, ~15% test\n",
    "\n",
    "train = df[df[\"date\"] <= train_end]\n",
    "val   = df[(df[\"date\"] > train_end) & (df[\"date\"] <= val_end)]\n",
    "test  = df[df[\"date\"] > val_end]\n",
    "\n",
    "len(train), len(val), len(test), n_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1049c5c3",
   "metadata": {},
   "source": [
    "feature_cols = [\n",
    "    c for c in df.columns\n",
    "    if c not in (\"date\", \"ticker\", \"target_ret\", \"target_logret\")\n",
    "]\n",
    "\n",
    "X_train, y_train = train[feature_cols], train[\"target_logret\"]\n",
    "X_val,   y_val   = val[feature_cols],   val[\"target_logret\"]\n",
    "X_test,  y_test  = test[feature_cols],  test[\"target_logret\"]\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb8718",
   "metadata": {},
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def eval_metrics(y_true, y_pred, name=\"\"):\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    print(f\"{name} RMSE={rmse:.6f}  MAE={mae:.6f}\")\n",
    "    return rmse, mae\n",
    "\n",
    "model_xgb = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "\n",
    "model_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "model_xgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "pred_val  = model_xgb.predict(X_val)\n",
    "pred_test = model_xgb.predict(X_test)\n",
    "\n",
    "rmse_val, mae_val   = eval_metrics(y_val,  pred_val,  \"XGB VAL\")\n",
    "rmse_test, mae_test = eval_metrics(y_test, pred_test, \"XGB TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2690c",
   "metadata": {},
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# série de logret1 indexée par date\n",
    "series = df.set_index(\"date\")[\"logret1\"].sort_index()\n",
    "\n",
    "train_s = series[series.index <= train_end].dropna()\n",
    "val_s   = series[(series.index > train_end) & (series.index <= val_end)].dropna()\n",
    "test_s  = series[series.index > val_end].dropna()\n",
    "\n",
    "len(train_s), len(val_s), len(test_s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c14a35",
   "metadata": {},
   "source": [
    "# ARIMA sur train, prévision sur val\n",
    "arima_model = ARIMA(train_s, order=(1, 0, 1))\n",
    "arima_res   = arima_model.fit()\n",
    "\n",
    "fc_val = arima_res.forecast(steps=len(val_s))\n",
    "fc_val.index = val_s.index  # aligner les index\n",
    "\n",
    "rmse_val_arima, mae_val_arima = eval_metrics(val_s, fc_val, \"ARIMA VAL\")\n",
    "\n",
    "# Refit sur train+val, prévision sur test\n",
    "trainval_s = series[series.index <= val_end].dropna()\n",
    "arima_model_tv = ARIMA(trainval_s, order=(1,0,1))\n",
    "arima_res_tv   = arima_model_tv.fit()\n",
    "\n",
    "fc_test = arima_res_tv.forecast(steps=len(test_s))\n",
    "fc_test.index = test_s.index\n",
    "\n",
    "rmse_test_arima, mae_test_arima = eval_metrics(test_s, fc_test, \"ARIMA TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c1f12f",
   "metadata": {},
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "df_prophet = (\n",
    "    df[[\"date\", \"logret1\"]]\n",
    "    .rename(columns={\"date\": \"ds\", \"logret1\": \"y\"})\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "train_p = df_prophet[df_prophet[\"ds\"] <= train_end]\n",
    "val_p   = df_prophet[(df_prophet[\"ds\"] > train_end) & (df_prophet[\"ds\"] <= val_end)]\n",
    "test_p  = df_prophet[df_prophet[\"ds\"] > val_end]\n",
    "\n",
    "m = Prophet(\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode=\"additive\",\n",
    ")\n",
    "m.fit(train_p)\n",
    "\n",
    "# Prévisions sur la validation\n",
    "fc_val_p = m.predict(val_p[[\"ds\"]])\n",
    "pred_val_p = fc_val_p[\"yhat\"].values\n",
    "\n",
    "rmse_val_prophet, mae_val_prophet = eval_metrics(val_p[\"y\"], pred_val_p, \"Prophet VAL\")\n",
    "\n",
    "# Refit sur train+val, prévisions sur test\n",
    "trainval_p = df_prophet[df_prophet[\"ds\"] <= val_end]\n",
    "m_tv = Prophet(\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode=\"additive\",\n",
    ")\n",
    "m_tv.fit(trainval_p)\n",
    "\n",
    "fc_test_p = m_tv.predict(test_p[[\"ds\"]])\n",
    "pred_test_p = fc_test_p[\"yhat\"].values\n",
    "\n",
    "rmse_test_prophet, mae_test_prophet = eval_metrics(test_p[\"y\"], pred_test_p, \"Prophet TEST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07472de3",
   "metadata": {},
   "source": [
    "print(df[\"logret1\"].std())\n",
    "print(df[\"logret1\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e3cf1",
   "metadata": {},
   "source": [
    "### Sauvegarde modèle ARIMA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53eb85d",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent          # ../ depuis notebooks/\n",
    "\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "arima_path = models_dir / \"arima_logret1_FCHI.pkl\"\n",
    "arima_res_tv.save(arima_path)\n",
    "\n",
    "print(\"ARIMA sauvegardé sous\", arima_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
